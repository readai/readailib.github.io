<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Matrix on ReadAILib Official Website </title>
    <link>/tags/matrix/</link>
    <description>Recent content in Matrix on ReadAILib Official Website </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Dec 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/matrix/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>多项式回归</title>
      <link>/2017/12/21/polynomial-regression/</link>
      <pubDate>Thu, 21 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/21/polynomial-regression/</guid>
      <description>该笔记是来自 Andrew Ng 的 Machine Learning 课程的第二周:多项式回归的课堂记录，有了合适的特征之后，我们发现线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，因此引出多项式回归模型，主要讲解了以下几个内容:
将多项式回归模型转换为线性模型正规方程将多项式回归模型转换为线性模型什么是多项式模型？比如一个二次模型\[h_{\theta} = \theta_{0} + \theta_{1}x + \theta_{2}x^2\],三次模型\[h_{\theta} = \theta_{0} + \theta_{1}x + \theta_{2}x^2 + \theta_{3}x^3\]
通常情况下，在模型进行选择时，首先要观察数据，然后再决定准备尝试什么样的模型，比如下面图 中的数据分布，我们可以通过观察可以看到，数据的分布用线性模型并不能达到很好的效果，所以在这里尝试用一个多项式模型来拟合我们的训练数据。
可以尝试多项式函数表示我们的模型：
\[h_{\theta} = \theta_{0} + \theta_{1}x + \theta_{2}x^2\]
或者
\[h_{\theta} = \theta_{0} + \theta_{1}x + \theta_{2}x^2 + \theta_{3}x^3\]
或者
\[h_{\theta} = \theta_{0} + \theta_{1}x + \theta_{2}x^{\frac{1}{2}}\]
有趣的是，如果我们对这些高次项进行替换，比如在\(h_{\theta} = \theta_{0} + \theta_{1}x + \theta_{2}x^2\)中，将 \[x_{2} := x^{2}\] 将可以转换为\(h_{\theta} = \theta_{0} + \theta_{1}x + \theta_{2}x_{2}\)，这样转换为多变量线性回归模型了。</description>
    </item>
    
    <item>
      <title>Display Image Using R</title>
      <link>/2017/12/19/display-image-using-r/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/19/display-image-using-r/</guid>
      <description>{r fig-margin, echo=FALSE, fig.cap=&amp;quot;这是一个神经网络的图。&amp;quot;, fig.height=3.5, fig.margin=TRUE, warning=FALSE, background=&amp;quot;#f5f5d5&amp;quot;, cache=FALSE}# need png packagelibrary(png)#Replace the directory and file information with your infoima &amp;lt;- readPNG(&amp;quot;C:\\Users\\Shine\\Desktop\\readailib\\themes\\hugo-lithium-theme\\static\\images\\logo.png&amp;quot;)grid::grid.raster(ima)Figure 1: 这是一个神经网络的图。</description>
    </item>
    
    <item>
      <title>利用python从头实现矩阵分解算法</title>
      <link>/2017/12/15/%E5%88%A9%E7%94%A8python%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%AE%97%E6%B3%95/</link>
      <pubDate>Fri, 15 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/15/%E5%88%A9%E7%94%A8python%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%AE%97%E6%B3%95/</guid>
      <description>该程序主要是我的《矩阵分析与应用》课程的大作业的解决方案及程序说明。大作业的要求为：
 要求完成课堂上讲的关于矩阵分解的LU、QR（Gram-Schmidt）、Orthogonal Reduction (Householder reduction 和Givens reduction)程序实现，要求如下：
 一个综合程序，根据选择参数的不同，实现不同的矩阵分解；
 可以用matlab等编写程序，需附上简单的程序说明，比如参数代表什么意思，输入什么，输出什么等等；
 一定是可执行文件，例如.m文件等,不能是word或者txt文档。附上源代码，不能为直接调用matlab等函数库.   程序说明 项目的地址为https://github.com/rh01/matrix-decomposition
- factorization.py - utils.py utils.py 共有两个源文件组成，其中utils文件主要是一些实现好的工具函数，有
def mult_matrix(M, N): &amp;quot;&amp;quot;&amp;quot;Multiply square matrices of same dimension M and N&amp;quot;&amp;quot;&amp;quot; def pivot_matrix(M): &amp;quot;&amp;quot;&amp;quot;Returns the pivoting matrix for M, used in Doolittle&amp;#39;s method.&amp;quot;&amp;quot;&amp;quot; def trans_matrix(M): &amp;quot;&amp;quot;&amp;quot;Take the transpose of a matrix.&amp;quot;&amp;quot;&amp;quot; def norm(x): &amp;quot;&amp;quot;&amp;quot;Return the Euclidean norm of the vector x.&amp;quot;&amp;quot;&amp;quot; def Q_i(Q_min, i, j, k): &amp;quot;&amp;quot;&amp;quot;Construct the Q_t matrix by left-top padding the matrix Q with elements from the identity matrix.</description>
    </item>
    
  </channel>
</rss>